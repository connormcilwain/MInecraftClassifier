{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90528e21",
   "metadata": {},
   "source": [
    "# Machine Learning - the k-Nearest Neighbours Algorithm<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0458439d",
   "metadata": {},
   "source": [
    "![Minecraft Steve and Creeper](data/msac.jpg)\n",
    "<h1><center>Friend or foe?</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2fcdb0",
   "metadata": {},
   "source": [
    "This notebook will teach you how to create a k-Nearest Neighbours machine learning algorithm. First, we'll train the model on our images of the Minecraft mobs. Then, once the model has learned which mobs are hostile, neutral or passive, we'll test the model on some never-before seen images to see if it can tell its behaviour!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf7ae57",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1400c6",
   "metadata": {},
   "source": [
    "Think about your best friend. Why do you like them? Are they funny, or kind, or athletic? Make a list in your head of all the qualities they have. Now think - do you share any of these qualities? Are **you** funny, or kind, or athletic? If you share a lot of qualities, you can think of them as your \"Nearest Neighbour\". The \"k\" in k-Nearest Neighbours is 1 in this case. If we thought about your two best friends, \"k\" would be 2. It simply means the number of neighbours.<br><br>Now, imagine a new kid moves to town who shares a lot of the qualities you and your friends have. Would you like to make friends with them? You might predict, \"Yes! If they are like me and my best friend, we'll probably get on well\". Now let's think about a similar situation for our machine learning model. If we can find some qualities that hostile Minecraft mobs share, we can look for those qualities in a new mob and predict if they're dangerous or not!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be5ae1",
   "metadata": {},
   "source": [
    "## Start here: How to use this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4177a991",
   "metadata": {},
   "source": [
    "Each box below contains some code we're going to run. We want to run each cell in order to make sure everything works. Try clicking on the box below. You should see a green outline appear around it. To run the code in the box, click the run button at the top of the page. Or, you can hold the shift key and press Enter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a55a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "import cv2 as cv\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn import neighbors\n",
    "%matplotlib inline\n",
    "print(\"All libraries Loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862570ed",
   "metadata": {},
   "source": [
    "If you see the `All libraries loaded!` message below the box, you've done it correctly - well done! Don't worry too much about the code in the box. We use it to load some extra code that will be working behind the scenes to assist us. <br><br>Try running the code in the box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3380b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "minecraft_steve = plt.imread(\"data/minecraft_steve.png\") # this line loads a picture\n",
    "plt.imshow(minecraft_steve) # this line shows the picture "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f17e02",
   "metadata": {},
   "source": [
    "You should now see a picture of Steve. Note the sentences following the `#` symbols - we use this method to add handy notes which explain what is going on in a particular piece of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089a3df",
   "metadata": {},
   "source": [
    "You're all set now! Let's get stuck in. Run each box of code in order. You can be sure it is a code box if you see `In [ ]:` to the left of the box. When you see `In [*]:` with the `*` in the brackets, it means the code is running. It might take a little bit of time to run all the code so don't worry if it's taking a long time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0022eb",
   "metadata": {},
   "source": [
    "## Who do I look most like? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e71048",
   "metadata": {},
   "source": [
    "To compare images, we need to understand how the computer looks at them. Run the code box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea16521",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_names = [\"steve\", \"creeper\", \"villager\"] \n",
    "character_faces = [plt.imread(\"data/\" + name + \".png\") for name in character_names]\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(nrows=1, ncols=3, figsize = (16,16))\n",
    "for ax, face, label in zip(fig.axes, character_faces, character_names):\n",
    "    ax.imshow(face)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(label, fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20bb489",
   "metadata": {},
   "source": [
    "You should now see 3 faces. Each face is made up of 100 individual coloured squares called \"pixels\". By combining green pixels and black pixels in a certain order, we can construct its face. Steve's face on the left is also made up of 100 pixels, but they are of different colours. <br><br>The third face on the right belongs to a villager. Do you think it is more similar to the creeper, or to Steve? You can probably guess, but can we help the computer to decide?<br><br>Well, each pixel has 3 numbers which tell us how strong the red, green and blue colours are for that individual pixel square. For example, the creeper has some really strong green pixel numbers, but almost zero red or blue pixel numbers. We can compare these numbers to determine how similar the images are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "how_similar_to_steve = np.sum(abs(character_faces[0] - character_faces[2])) \n",
    "how_similar_to_creeper = np.sum(abs(character_faces[1] - character_faces[2]))\n",
    "nearest_neighbour = min(how_similar_to_steve, how_similar_to_creeper)\n",
    "print(f\"Distance from Steve is {int(how_similar_to_steve)}. Distance from Creeper is {int(how_similar_to_creeper)}.\"\n",
    "      f\" Nearest neighbour is Steve!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67109daa",
   "metadata": {},
   "source": [
    "All we have done here is subtract the pixel numbers of the villager from both Steve and the creeper. The smaller the value of the distance is, the more similar the pixels contained in that image are. But instead of \"Steveiness\" and \"Creepiness\", we want our model to figure out whether a photo you give is contains a mob that is hostile, neutral or passive. And, instead of using three photos to decide, we're going to use the power of computers to test thousands! Let's load all of our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79082aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImageFiles(image_storage_path):\n",
    "# Block 1\n",
    "    image_storage_folder = Path(image_storage_path)\n",
    "    folders = [directory for directory in image_storage_folder.iterdir() if directory.is_dir()]\n",
    "    categories = [folder.name for folder in folders]\n",
    "    \n",
    "#Block 2\n",
    "    image_array = []\n",
    "    for folder in folders:\n",
    "        for file in folder.iterdir():\n",
    "            image = cv.imread(str(file))\n",
    "            image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "            image = cv.resize(image, (50, 50), interpolation=cv.INTER_AREA) / 255\n",
    "            image_array.append(image)\n",
    "    image_array = np.array(image_array)\n",
    "    return image_array, categories\n",
    "\n",
    "\n",
    "#Block 3\n",
    "def ResizeImages(image_array):\n",
    "    image_array = image_array.reshape(len(image_array), 50*50)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b71996",
   "metadata": {},
   "source": [
    "Don't worry if this code looks more complicated than last time; let's try and understand what each block is doing for now. `#Block 1` finds where our image folders are and reads their names out. `#Block 2` goes through every image in the folder and loads it to our program. We convert the image to gray and make it smaller to help our program run even faster. `#Block 3` finally flattens all the pixels into a big list of pixel values for each image and spits it back out. Think of it like a shopping list where each line has only one item you need. Run the code below to flatten the creeper and see what I'm talking about!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax4, ax5] = plt.subplots(nrows=1, ncols=2, figsize = (16,16))\n",
    "ax4.imshow(character_faces[1])\n",
    "ax4.axis('off')\n",
    "ax4.set_title('creeper', fontsize=20)\n",
    "ax5.imshow(character_faces[1].flatten().reshape(1, 100, 3))\n",
    "ax5.axis('off')\n",
    "ax5.set_title('flat creeper', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e9f61",
   "metadata": {},
   "source": [
    "\n",
    "The very top line, `def LoadImageFiles(container_path):` is kind of like the name of this block of code. We can call its name `LoadImageFiles` in another code box and give it the location of some images saved to our computer, and it will automatically run through all the code and load the images without having to write everything out again! Pretty handy! The same goes for `def ResizeImages(image_array):` in Block 3. Let's do that again for another useful function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea901f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LabelsToNumbers(image_folder, labels):\n",
    "    for i, behaviour in enumerate(labels):\n",
    "        directory = image_folder + '/' + behaviour\n",
    "        label_array = np.full(len([name for name in os.listdir(directory)]), i, dtype = 'int')\n",
    "        if i == 0:\n",
    "            labels_as_numbers = label_array\n",
    "        else:\n",
    "            labels_as_numbers = np.append(labels_as_numbers, label_array)\n",
    "    return labels_as_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e234d61",
   "metadata": {},
   "source": [
    "`LabelsToNumbers` is doing exactly what it says. Our labels for each kind of mob are `['hostile', 'neutral', 'passive']`. Computers find it harder to read words than they do to read numbers, so we simply swap each label for a number `[0, 1, 2]` where hostile is 0, neutral is 1 and passive is 2. This lets our program run much faster!\n",
    "\n",
    "Now, let's use our functions we just wrote to load all our images, and turn their labels into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images to train with #\n",
    "training_image_folder = \"images/Images to Train With\"\n",
    "images, labels = LoadImageFiles(training_image_folder)\n",
    "images_flattened = ResizeImages(images)\n",
    "labels_as_numbers = LabelsToNumbers(training_image_folder, labels)\n",
    "\n",
    "# Load images to test with #\n",
    "testing_image_folder = \"images/Images to Test With\"\n",
    "test_images, test_labels = LoadImageFiles(testing_image_folder)\n",
    "test_images_flattened = ResizeImages(test_images)\n",
    "test_labels_as_numbers = LabelsToNumbers(testing_image_folder, test_labels)\n",
    "\n",
    "print(\"Images Loaded Successfully!\")\n",
    "\n",
    "# Show some random images #\n",
    "plt.figure(1, figsize=(15, 9))\n",
    "plt.axis('off')\n",
    "n = 0\n",
    "for i in range(16):\n",
    "  n += 1\n",
    "  random_image = random.choice(images)\n",
    "  plt.subplot(4, 4, n)\n",
    "  plt.axis('off')\n",
    "  plt.imshow(random_image, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab657f2",
   "metadata": {},
   "source": [
    "See any mobs you recognise? Remember we loaded all the images as gray and made them smaller!<br><br>Now, let's return to thinking about the nearest neighbours. Remember when we subtracted the images previously to determine their distances from each other? That's not the only way of determining how similar images are. We will use the dreaded (and extremely useful) Pythagoras's Theorem to measure this instead. So if you're bored learning about it in math class, remember it can be used to teach computers how to think!<br><br>We've loaded in our training images, like we loaded the pictures of Steve and the Creeper. We've loaded in our testing image, like we loaded the picture of the villager. Now, instead of testing just one image, we're going to calculate the nearest neighbor for every single image and see how many times it guesses right! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,10):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors = i)\n",
    "    print(f'For k = {i}, KNN score is {int(len(test_images)*(knn.fit(images_flattened, labels_as_numbers).score(test_images_flattened, test_labels_as_numbers)))} / {len(test_images)} ({100*knn.fit(images_flattened, labels_as_numbers).score(test_images_flattened, test_labels_as_numbers):.1f}% accuracy)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af086bfa",
   "metadata": {},
   "source": [
    "So when k = 1, we have our best prediction with almost one half correct! This might not seem like a lot, but if we were to randomly guess which mob belonged to which class, we expect our accuracy to be 33% or one third. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f8932",
   "metadata": {},
   "source": [
    "## How to improve our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64156487",
   "metadata": {},
   "source": [
    "One way to improve our results would be to look at the images in color and factor that when calculating distance of neighbors. \n",
    "However, k-Nearest Neighbours *does not actually learn*. It's more like if you wrote all the answers down for a test and looked at your page for the answers, instead of figuring out the answer on your own. It's also not the best method for classifying images like ours with text, weird graphics and other random things that aren't mobs: It gets a little confused. If you want to see some code that learns and improves in accuracy, check out the \"Hard Mode\" tutorial to learn about Convolutional Neural Networks and see some really powerful predictions!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45bfbd7",
   "metadata": {},
   "source": [
    "![Minecraft Steve dance](data/stevedance.gif)\n",
    "<h1><center>Thanks for playing!</center></h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
